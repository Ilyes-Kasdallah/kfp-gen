{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBL2_qM49rly"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "generated_dir = Path(\"kfp_eval_samples\")\n",
        "reference_dir = Path(\"saved_kfp_files\")\n",
        "\n",
        "def normalize_name(name):\n",
        "    return re.sub(r'[-_\\.]|\\.py$', '', name.lower())\n",
        "\n",
        "def create_name_map(folder):\n",
        "    name_map = {}\n",
        "    for file in folder.glob(\"*.py\"):\n",
        "        norm = normalize_name(file.stem)\n",
        "        name_map[norm] = str(file)\n",
        "    return name_map\n",
        "\n",
        "generated_map = create_name_map(generated_dir)\n",
        "reference_map = create_name_map(reference_dir)\n",
        "\n",
        "common_keys = set(generated_map.keys()) & set(reference_map.keys())\n",
        "\n",
        "print(f\"âœ… Found {len(common_keys)} matching files.\")\n",
        "\n",
        "# Save to JSON for the second script\n",
        "with open(\"matched_files.json\", \"w\") as f:\n",
        "    json.dump([\n",
        "        {\"key\": key, \"generated\": generated_map[key], \"reference\": reference_map[key]}\n",
        "        for key in common_keys\n",
        "    ], f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "# Load matched files\n",
        "with open(\"matched_files.json\", \"r\") as f:\n",
        "    matched_files = json.load(f)\n",
        "\n",
        "def remove_comments_and_docstrings(code):\n",
        "    code = re.sub(r'(?m)^ *#.*\\n?', '', code)\n",
        "    code = re.sub(r'\"\"\"[\\s\\S]*?\"\"\"', '', code)\n",
        "    code = re.sub(r\"'''[\\s\\S]*?'''\", '', code)\n",
        "    return code\n",
        "\n",
        "smooth = SmoothingFunction().method1\n",
        "references = []\n",
        "hypotheses = []\n",
        "\n",
        "for item in matched_files:\n",
        "    with open(item[\"generated\"], \"r\", encoding=\"utf-8\") as f:\n",
        "        gen = remove_comments_and_docstrings(f.read())\n",
        "    with open(item[\"reference\"], \"r\", encoding=\"utf-8\") as f:\n",
        "        ref = remove_comments_and_docstrings(f.read())\n",
        "\n",
        "    gen_tokens = gen.split()\n",
        "    ref_tokens = ref.split()\n",
        "\n",
        "    hypotheses.append(gen_tokens)\n",
        "    references.append([ref_tokens])  # Corpus BLEU expects a list of reference lists\n",
        "\n",
        "# Compute a single BLEU score\n",
        "score = corpus_bleu(references, hypotheses, smoothing_function=smooth)\n",
        "print(f\"Overall BLEU score for Qwen-generated KFPs: {round(score, 4)}\")\n"
      ],
      "metadata": {
        "id": "236lhIhQ9_k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}