You are an MLOps engineer. Write a Kubeflow pipeline based on the following description and code logic:

A pipeline to generate and tag conversations given a situation          .. _p_generate_and_tag_conversations:      Example payload to invoke via slack integrations:      A minimal example:          @charon run generate_and_tag_conversations          .. code-block:: python              {   "situations" : "The user disputes the debt, so the agent transfers the call to the agent :: The user cannot pay any amount as they have a difficult situation, so the agent hangs up the call. ",                 "scenario" : "Test scenario",                 "scenario_category" : "Test scenario category",                 "llm_trainer_repo_branch" : "refactor-data-gen-script",                 "client_id" : "85",                 "template_id" : "0",                 "labelstudio_project_id" : "95",                 "s3_links_to_prompts": "s3://kubeflow-us-cluster/pipeline_uploads/prompt/test_prompt.txt",                 "data_label" : "UAT",                 "project_name" : "test project name"             }       A full available parameters example:          @charon run generate_and_tag_conversations          .. code-block:: python              {   "situations" : "The user disputes the debt, so the agent transfers the call to the agent :: The user cannot pay any amount as they have a difficult situation, so the agent hangs up the call. ",                 "scenario" : "Test scenario",                 "scenario_category" : "Test scenario category",                 "llm_trainer_repo_branch" : "refactor-data-gen-script",                 "client_id" : "85",                 "template_id" : "0",                 "labelstudio_project_id" : "95",                 "s3_links_to_prompts": "s3://kubeflow-us-cluster/pipeline_uploads/prompt/test_prompt.txt",                 "data_label" : "UAT",                 "project_name" : "test project name"             }          :param situations: The situations for generating the conversations, use delimiter :: to pass multiple situations     :type situations: optional      :param scenario: The scenario linked to the situation     :type scenario: optional          :param scenario_category: The scenarios category     :type scenario_category: optional          :param prompt: Prompt to the model for data generation     type prompt: str          :param s3_links_to_prompts: s3 links to the prompt to the model for data generation     :type s3_links_to_prompts: str          :param output_dir: The output directory where the generated conversations gets stored     :type output_dir: str      :param filename: Acts as a prfix to the default naming used     :type filename: str      :param llm_trainer_repo_name: The conversation generation repo name in Github.     :type llm_trainer_repo_name: str          :param llm_trainer_repo_branch: The branch name in the conversation generation repo to use , defaults to main.     :type llm_trainer_repo_branch: str, optional          :param model: Optional model to be used for generating data      :type model: str          :param n_iter: No of times we make iterate on scenarios list to generate conversations     type n_iter: int          :param n_choice: No of convs generated in a single time from a scenario.     type n_choice: int          :param temperature: Temperature     type temperature: float          :param client_id: id of the client for which data is being generated     :type client_id : str          :param template_id: template id for which data is being generated     :type template_id : str          :param project_name: project name to distinguish between various experiments     :type project_name : str          :param notify: Whether to send a slack notification, defaults to ""     :type notify: str, optional      :param channel: The slack channel to send the notification, defaults to ""     :type channel: str, optional      :param slack_thread: The slack thread to send the notification, defaults to ""     :type slack_thread: str, optional