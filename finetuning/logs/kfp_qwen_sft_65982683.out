Node Python: 3.11.5
Torch CUDA: 12.2 Devices: 1
bnb libs: ['libbitsandbytes_cuda122.so', 'libbitsandbytes_cuda122_nocublaslt.so']
bitsandbytes: 0.43.3 OK
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.7
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
  0%|          | 0/56 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  2%|â–         | 1/56 [00:30<28:06, 30.67s/it]  4%|â–Ž         | 2/56 [00:42<17:35, 19.56s/it]  5%|â–Œ         | 3/56 [00:50<12:41, 14.37s/it]  7%|â–‹         | 4/56 [01:05<12:36, 14.55s/it]  9%|â–‰         | 5/56 [01:17<11:38, 13.69s/it] 11%|â–ˆ         | 6/56 [01:24<09:35, 11.51s/it] 12%|â–ˆâ–Ž        | 7/56 [01:39<10:16, 12.59s/it] 14%|â–ˆâ–        | 8/56 [01:52<10:13, 12.79s/it] 16%|â–ˆâ–Œ        | 9/56 [02:01<09:02, 11.55s/it] 18%|â–ˆâ–Š        | 10/56 [02:16<09:37, 12.56s/it] 20%|â–ˆâ–‰        | 11/56 [02:28<09:21, 12.47s/it] 21%|â–ˆâ–ˆâ–       | 12/56 [02:36<08:03, 10.99s/it] 23%|â–ˆâ–ˆâ–Ž       | 13/56 [02:48<08:09, 11.39s/it] 25%|â–ˆâ–ˆâ–Œ       | 14/56 [02:58<07:36, 10.88s/it] 27%|â–ˆâ–ˆâ–‹       | 15/56 [03:04<06:26,  9.42s/it] 29%|â–ˆâ–ˆâ–Š       | 16/56 [03:18<07:15, 10.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 17/56 [03:29<07:06, 10.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 18/56 [03:37<06:22, 10.06s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 19/56 [03:52<07:03, 11.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [04:01<06:30, 10.86s/it]                                                36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20/56 [04:01<06:30, 10.86s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 21/56 [04:08<05:36,  9.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 22/56 [04:23<06:20, 11.20s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23/56 [04:36<06:29, 11.81s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24/56 [04:45<05:45, 10.79s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25/56 [05:00<06:12, 12.01s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26/56 [05:13<06:14, 12.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27/56 [05:23<05:34, 11.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28/56 [05:37<05:44, 12.29s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/56 [05:47<05:16, 11.71s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 30/56 [05:53<04:20, 10.01s/it]{'loss': 7.643, 'grad_norm': 2.7942757606506348, 'learning_rate': 7.500000000000001e-05, 'epoch': 1.34}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31/56 [06:08<04:47, 11.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32/56 [06:20<04:41, 11.74s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 33/56 [06:29<04:06, 10.70s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34/56 [06:43<04:18, 11.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35/56 [06:54<04:01, 11.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36/56 [07:01<03:27, 10.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 37/56 [07:16<03:42, 11.73s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 38/56 [07:28<03:32, 11.83s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39/56 [07:37<03:02, 10.76s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/56 [07:51<03:11, 11.97s/it]                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/56 [07:51<03:11, 11.97s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41/56 [08:02<02:53, 11.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42/56 [08:09<02:23, 10.25s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 43/56 [08:24<02:31, 11.65s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 44/56 [08:36<02:20, 11.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 45/56 [08:42<01:49,  9.95s/it]{'loss': 6.0238, 'grad_norm': 1.6041007041931152, 'learning_rate': 2.0142070414860704e-05, 'epoch': 2.68}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 46/56 [08:57<01:54, 11.49s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47/56 [09:11<01:50, 12.32s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 48/56 [09:21<01:31, 11.47s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49/56 [09:35<01:27, 12.44s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 50/56 [09:46<01:11, 11.97s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 51/56 [09:54<00:52, 10.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 52/56 [10:08<00:46, 11.74s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53/56 [10:18<00:33, 11.13s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 54/56 [10:25<00:19,  9.97s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 55/56 [10:40<00:11, 11.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [10:52<00:00, 11.57s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [10:53<00:00, 11.57s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [10:53<00:00, 11.67s/it]
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:         train/epoch â–â–…â–ˆ
wandb:   train/global_step â–â–…â–ˆ
wandb:     train/grad_norm â–ˆâ–
wandb: train/learning_rate â–ˆâ–
wandb:          train/loss â–ˆâ–
wandb: 
wandb: Run summary:
wandb:               total_flos 1.999351522215936e+16
wandb:              train/epoch 3.74576
wandb:        train/global_step 56
wandb:          train/grad_norm 1.6041
wandb:      train/learning_rate 2e-05
wandb:               train/loss 6.0238
wandb:               train_loss 6.52225
wandb:            train_runtime 653.517
wandb: train_samples_per_second 0.722
wandb:   train_steps_per_second 0.086
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync run/kfp-Qwen2.5-7B-Instruct/wandb/offline-run-20250816_220249-s7y3h0n0
wandb: Find logs at: run/kfp-Qwen2.5-7B-Instruct/wandb/offline-run-20250816_220249-s7y3h0n0/logs
{'train_runtime': 653.517, 'train_samples_per_second': 0.722, 'train_steps_per_second': 0.086, 'train_loss': 6.522247178213937, 'epoch': 3.75}
