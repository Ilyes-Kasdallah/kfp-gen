WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122_nocublaslt122.so.
This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.
If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=
If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH
For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64

Could not find the bitsandbytes CUDA binary at PosixPath('/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt122.so')
The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
Node Python: 3.11.5
Torch CUDA: 12.2 Devices: 1
bitsandbytes: 0.43.3 OK
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.18.7
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122_nocublaslt122.so.
This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.
If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=
If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH
For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64

Could not find the bitsandbytes CUDA binary at PosixPath('/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt122.so')
The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
Traceback (most recent call last):
  File "/scratch/ilyes/kfp-gen/finetuning/unsloth_trainer/train_sft.py", line 149, in <module>
    main(args)
  File "/scratch/ilyes/kfp-gen/finetuning/unsloth_trainer/train_sft.py", line 47, in main
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4224, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4794, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/modeling_utils.py", line 875, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py", line 242, in create_quantized_param
    new_value = bnb.nn.Params4bit(new_value, requires_grad=False, **kwargs).to(target_device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/nn/modules.py", line 332, in to
    return self._quantize(device)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/nn/modules.py", line 297, in _quantize
    w_4bit, quant_state = bnb.functional.quantize_4bit(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/functional.py", line 1210, in quantize_4bit
    lib.cquantize_blockwise_fp16_nf4(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/cextension.py", line 73, in __getattr__
    return getattr(self._lib, item)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.11.5/lib/python3.11/ctypes/__init__.py", line 389, in __getattr__
    func = self.__getitem__(name)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.11.5/lib/python3.11/ctypes/__init__.py", line 394, in __getitem__
    func = self._FuncPtr((name_or_ordinal, self))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: /home/ilyes/ENV311/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cquantize_blockwise_fp16_nf4
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync run/kfp-Qwen2.5-7B-Instruct/wandb/offline-run-20250815_204622-dz0sao6e[0m
