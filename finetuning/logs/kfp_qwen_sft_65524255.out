wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.7
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[2025-08-08 15:55:28,072] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
  0%|          | 0/21 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  5%|▍         | 1/21 [00:22<07:39, 22.95s/it] 10%|▉         | 2/21 [00:30<04:18, 13.61s/it] 14%|█▍        | 3/21 [00:36<03:09, 10.54s/it] 19%|█▉        | 4/21 [00:43<02:34,  9.11s/it] 24%|██▍       | 5/21 [00:50<02:13,  8.31s/it] 29%|██▊       | 6/21 [00:57<01:57,  7.84s/it] 33%|███▎      | 7/21 [01:04<01:46,  7.58s/it] 38%|███▊      | 8/21 [01:11<01:35,  7.37s/it] 43%|████▎     | 9/21 [01:18<01:26,  7.23s/it] 48%|████▊     | 10/21 [01:25<01:18,  7.14s/it]                                                48%|████▊     | 10/21 [01:25<01:18,  7.14s/it] 52%|█████▏    | 11/21 [01:32<01:10,  7.09s/it] 57%|█████▋    | 12/21 [01:39<01:03,  7.04s/it] 62%|██████▏   | 13/21 [01:46<00:56,  7.01s/it] 67%|██████▋   | 14/21 [01:53<00:49,  7.02s/it] 71%|███████▏  | 15/21 [02:00<00:41,  6.99s/it] 76%|███████▌  | 16/21 [02:07<00:34,  6.98s/it] 81%|████████  | 17/21 [02:14<00:27,  6.97s/it] 86%|████████▌ | 18/21 [02:21<00:20,  6.96s/it] 90%|█████████ | 19/21 [02:28<00:13,  6.96s/it] 95%|█████████▌| 20/21 [02:35<00:06,  6.99s/it]                                                95%|█████████▌| 20/21 [02:35<00:06,  6.99s/it]100%|██████████| 21/21 [02:42<00:00,  6.98s/it]                                               100%|██████████| 21/21 [02:43<00:00,  6.98s/it]100%|██████████| 21/21 [02:43<00:00,  7.77s/it]
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:         train/epoch ▁▇█
wandb:   train/global_step ▁▇█
wandb:     train/grad_norm █▁
wandb: train/learning_rate █▁
wandb:          train/loss █▁
wandb: 
wandb: Run summary:
wandb:               total_flos 7319071393579008.0
wandb:              train/epoch 1
wandb:        train/global_step 21
wandb:          train/grad_norm 0.77602
wandb:      train/learning_rate 2e-05
wandb:               train/loss 2.8768
wandb:               train_loss 3.27992
wandb:            train_runtime 163.258
wandb: train_samples_per_second 0.515
wandb:   train_steps_per_second 0.129
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync run/kfp-Qwen2.5-7B-Instruct/wandb/offline-run-20250808_155102-wst0sxwl
wandb: Find logs at: run/kfp-Qwen2.5-7B-Instruct/wandb/offline-run-20250808_155102-wst0sxwl/logs
{'loss': 3.6851, 'grad_norm': 0.8278194665908813, 'learning_rate': 0.0002619047619047619, 'epoch': 0.48}
{'loss': 2.8768, 'grad_norm': 0.7760220170021057, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.95}
{'train_runtime': 163.258, 'train_samples_per_second': 0.515, 'train_steps_per_second': 0.129, 'train_loss': 3.2799195107959567, 'epoch': 1.0}
